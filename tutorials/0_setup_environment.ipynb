{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can install python and torch using any way you like, but we advise you to use micromamba (or conda). Here is the command used to make our development environment.\n",
    "\n",
    "```bash\n",
    "micromamba env create --prefix ~/env_plaqntt_release/ python pytorch==2.4.0 torchvision torchaudio pytorch-cuda jupyterlab librosa tensorboard ipywidgets torchvision gcc\\<13.0.0 libgcc-ng\\<13.0.0 gxx_linux-64\\<13.0.0 -c pytorch -c nvidia -c conda-forge\n",
    "```\n",
    "\n",
    "We include gcc/gxx etc for the compilation of the Mamba package.\n",
    "\n",
    "You can refer to the [reference_environment/](reference_environment) folder for the details of the versions of each package we used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once your environment is created, please install the plaqntt package. You can do so by running the following command in the root folder of the repository:\n",
    "\n",
    "```bash\n",
    "pip install -e .\n",
    "```\n",
    "\n",
    "Finally for the notebooks maybe you'll have to run\n",
    "\n",
    "```bash\n",
    "python -m ipykernel install --user --name plaqnttenv --display-name \"Python (plaqntt)\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we can test if the model loads correctly (you will need a GPU as Mamba is not implemented for CPUs for now)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyannote.audio import Model\n",
    "\n",
    "mamba_diar = Model.from_pretrained('idk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pyannote.audio\n",
    "import torchaudio\n",
    "\n",
    "wavfilepath = os.path.join(pyannote.audio.__path__[0], 'sample', 'sample.wav')\n",
    "waveform, sample_rate = torchaudio.load(wavfilepath)\n",
    "waveform.shape, sample_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mamba_diar(waveform)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
